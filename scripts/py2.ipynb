{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    import re\n",
    "    \" removes urls\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    links_lst = re.findall(url_pattern, text)\n",
    "    return re.sub(url_pattern, \"\", text), links_lst # URL_MASK\n",
    "    \n",
    "def remove_parentheses(text):\n",
    "    import re\n",
    "    \" removes parentheses\"\n",
    "    para_pattern = re.compile(r'\\(.*?\\)')\n",
    "    para_lst = [re.sub(\"[\\\\(\\\\)]\", \"\", x).strip() for x in re.findall(para_pattern, text)]\n",
    "    return re.sub(para_pattern, \"\", text), para_lst # PARENTHESES_MASK\n",
    "    \n",
    "def remove_html(text):\n",
    "    import re\n",
    "    \" removes html tags\"\n",
    "    html_pattern = re.compile('')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_new_line(text):\n",
    "    import re\n",
    "    return re.sub(r\"\\\\\\n\", ' ', text)\n",
    "\n",
    "def remove_non_alpha(text):\n",
    "    import re\n",
    "    return re.sub(\"[^A-Za-z0-9\\\\.\\\\_]+\", ' ', str(text))\n",
    "\n",
    "def fix_these_data(text, fix_lst):\n",
    "    import re\n",
    "    for x in fix_lst:\n",
    "        text = re.sub(x[0], x[1], text)\n",
    "    text = re.sub(\"\\\\(\", \" ( \", text)\n",
    "    text = re.sub(\"\\\\)\", \" ) \", text)\n",
    "    text = re.sub(\"\\\\.\\\\\\n\", \" \", text)\n",
    "    text = re.sub(\"\\\\\\\"\", \" \", text)\n",
    "    text = re.sub(\"\\\\\\'\", \" \", text)\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def remove_extra_periods(text):\n",
    "    import re\n",
    "    pat = re.compile('\\\\.')\n",
    "    txt_lst = re.sub(pat, \" NJ3CT_H3R3 \", text).split(\"NJ3CT_H3R3\")\n",
    "    hodl_string = \" \".join(txt_lst)\n",
    "    \n",
    "    if len(txt_lst) > 1:\n",
    "        temp_lst = []\n",
    "        hodl_string = \"\"\n",
    "        for txt_part in txt_lst:\n",
    "            txt_part = txt_part.strip()\n",
    "            if len(txt_part) > 0:\n",
    "                if txt_part[0] == txt_part[0].lower():\n",
    "                    hodl_string = hodl_string + \" \" + txt_part\n",
    "                else:\n",
    "                    hodl_string = hodl_string + \". \" + txt_part\n",
    "                    if hodl_string[0] == \".\":\n",
    "                        hodl_string = hodl_string[1:]\n",
    "    return hodl_string.strip()\n",
    "\n",
    "def preprocess_text(t): #[\" UK \", \" United Kingdom \"], [\" U\\\\.K\\\\. \", \" United Kingdom \"], [\" U\\\\. K\\\\. \", \" United Kingdom \"], [\" U K \", \" United Kingdom \"], [\" U\\\\. S\\\\. \", \" United States \"], [\" US \", \" United States \"], [\" U S \", \" United States \"], [\" U\\\\.S\\\\. \", \" United States \"], \n",
    "    # contraction_lst = [[\"&quot\", \"\"], [\" can\\\\\\'t \",  \" can not \"], [\" let\\\\\\'s \",  \" let us \"], [\" won\\\\\\'t \",  \" will not \"], [\" n\\\\\\'t \",  \"  not \"], [\" \\\\\\'m \",  \"  am \"], [\" \\\\\\'s \",  \"  is \"], [\" \\\\\\'re \",  \"  are \"], [\" \\\\\\'ve \",  \"  have \"], [\" \\\\\\'d \",  \"  had \"], [\" \\\\\\'ll \",  \"  will \"], [\" arent \",  \" are not \"], [\" cant \",  \" cannot \"], [\" couldnt \",  \" could not \"], [\" didnt \",  \" did not \"], [\" doesnt \",  \" does not \"], [\" dont \",  \" do not \"], [\" hadnt \",  \" had not \"], [\" hasnt \",  \" has not \"], [\" havent \",  \" have not \"], [\" hed \",  \" he had \"], [\" hes \",  \" he is \"], [\" Id \",  \" I would \"], [\" Ill \",  \" I will \"], [\" Im \",  \" I am \"], [\" Ive \",  \" I have \"], [\" isnt \",  \" is not \"], [\" lets \",  \" let us \"], [\" mightnt \",  \" might not \"], [\" mustnt \",  \" must not \"], [\" shant \",  \" shall not \"], [\" shed \",  \" she had \"], [\" shes \",  \" she is \"], [\" shouldnt \",  \" should not \"], [\" thats \",  \" that is \"], [\" theres \",  \" there is \"], [\" theyd \",  \" they had \"], [\" theyll \",  \" they will \"], [\" theyre \",  \" they are \"], [\" theyve \",  \" they have \"], [\" wed \",  \" we had \"], [\" were \",  \" we are \"], [\" weve \",  \" we have \"], [\" werent \",  \" were not \"], [\" whatll \",  \" what will \"], [\" whatre \",  \" what are \"], [\" whats \",  \" what is \"], [\" whatve \",  \" what have \"], [\" wheres \",  \" where is \"], [\" whod \",  \" who had \"], [\" wholl \",  \" who will \"], [\" whore \",  \" who are \"], [\" whos \",  \" who is \"], [\" whove \",  \" who have \"], [\" wont \",  \" will not \"], [\" wouldnt \",  \" would not \"], [\" youd \",  \" you had \"], [\" youll \",  \" you will \"], [\" youre \",  \" you are \"], [\" youve \",  \" you have \"]]\n",
    "    contraction_lst = [[\" cant \",  \" can not \"], [\" lets \",  \" let us \"], [\" wont \",  \" will not \"], [\" nt \",  \"  not \"], [\" m \",  \"  am \"], [\" s \",  \"  is \"], [\" re \",  \"  are \"], [\" ve \",  \"  have \"], [\" d \",  \"  had \"], [\" ll \",  \"  will \"], [\" arent \",  \" are not \"], [\" cant \",  \" cannot \"], [\" couldnt \",  \" could not \"], [\" didnt \",  \" did not \"], [\" doesnt \",  \" does not \"], [\" dont \",  \" do not \"], [\" hadnt \",  \" had not \"], [\" hasnt \",  \" has not \"], [\" havent \",  \" have not \"], [\" hed \",  \" he had \"], [\" hes \",  \" he is \"], [\" Id \",  \" I would \"], [\" Ill \",  \" I will \"], [\" Im \",  \" I am \"], [\" Ive \",  \" I have \"], [\" isnt \",  \" is not \"], [\" lets \",  \" let us \"], [\" mightnt \",  \" might not \"], [\" mustnt \",  \" must not \"], [\" shant \",  \" shall not \"], [\" shed \",  \" she had \"], [\" shes \",  \" she is \"], [\" shouldnt \",  \" should not \"], [\" thats \",  \" that is \"], [\" theres \",  \" there is \"], [\" theyd \",  \" they had \"], [\" theyll \",  \" they will \"], [\" theyre \",  \" they are \"], [\" theyve \",  \" they have \"], [\" wed \",  \" we had \"], [\" were \",  \" we are \"], [\" weve \",  \" we have \"], [\" werent \",  \" were not \"], [\" whatll \",  \" what will \"], [\" whatre \",  \" what are \"], [\" whats \",  \" what is \"], [\" whatve \",  \" what have \"], [\" wheres \",  \" where is \"], [\" whod \",  \" who had \"], [\" wholl \",  \" who will \"], [\" whore \",  \" who are \"], [\" whos \",  \" who is \"], [\" whove \",  \" who have \"], [\" wont \",  \" will not \"], [\" wouldnt \",  \" would not \"], [\" youd \",  \" you had \"], [\" youll \",  \" you will \"], [\" youre \",  \" you are \"], [\" youve \",  \" you have \"]]\n",
    "    t = fix_these_data(t, contraction_lst)\n",
    "    t, link_lst = remove_urls(t)\n",
    "    t, para_lst = remove_parentheses(t)\n",
    "    t = remove_extra_periods(t)\n",
    "    t = remove_html(t)\n",
    "    t = remove_new_line(t)\n",
    "    t = remove_non_alpha(t)\n",
    "    return t.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "data_pth = \"N:/Classes/2022_2FALL/Analytics Day/Code/output_results.csv\"\n",
    "\n",
    "df = pd.read_csv(data_pth).drop(\"Unnamed: 0\", axis = 1)\n",
    "\n",
    "df[\"scale\"] = 0\n",
    "\n",
    "df.loc[df[\"STUDSENT_label_rComments_tags\"] == \"NEGATIVE\", \"scale\"] = 1\n",
    "\n",
    "df[\"STUDSENT_score_rComments_tags\"] = df[\"scale\"] + df[\"STUDSENT_score_rComments_tags\"]\n",
    "\n",
    "df[df[\"STUDSENT_label_rComments_tags\"] == \"NEGATIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPEID                                                                       154100\n",
       "school_sid                                                                       2\n",
       "INSTNM                                        Abraham Baldwin Agricultural College\n",
       "school_year                                                                2002_03\n",
       "WDRAW_ORIG_YR2_RT                                                         0.244068\n",
       "STUDSENT_label_rComments_tags    [POSITIVE, POSITIVE, POSITIVE, POSITIVE, POSIT...\n",
       "STUDSENT_score_rComments_tags    [0.6046267151832581, 0.9998801946640016, 0.999...\n",
       "AVGSTUDSENT                                                               0.800646\n",
       "all_rComments_tags               She has a great personality very real person. ...\n",
       "POSITIVE_count                                                                   6\n",
       "NEGATIVE_count                                                                   1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_df = df[[\"OPEID\", \"school_sid\", \"INSTNM\", \"school_year\", \"WDRAW_ORIG_YR2_RT\", \"rComments_tags\", \"STUDSENT_label_rComments_tags\", \"STUDSENT_score_rComments_tags\"]].groupby([\"OPEID\", \"school_sid\", \"INSTNM\", \"school_year\", \"WDRAW_ORIG_YR2_RT\"]).agg(list).reset_index()\n",
    "\n",
    "\n",
    "gr_df[\"AVGSTUDSENT\"] = [statistics.mean(x) for x in gr_df[\"STUDSENT_score_rComments_tags\"]]\n",
    "gr_df[\"all_rComments_tags\"] = [\" \".join(x).replace(\"[]\", \"\") for x in gr_df[\"rComments_tags\"]]\n",
    "\n",
    "gr_df = gr_df.drop([\"rComments_tags\"], axis = 1) # , \"STUDSENT_score_rComments_tags\"\n",
    "\n",
    "gr_df[\"all_rComments_tags\"] = gr_df[\"all_rComments_tags\"].apply(preprocess_text)\n",
    "\n",
    "gr_df.STUDSENT_label_rComments_tags.iloc[0].count(\"POSITIVE\")\n",
    "gr_df.STUDSENT_label_rComments_tags.iloc[0].count(\"NEGATIVE\")\n",
    "\n",
    "gr_df[\"POSITIVE_count\"] = [x.count(\"POSITIVE\") for x in gr_df[\"STUDSENT_label_rComments_tags\"]]\n",
    "gr_df[\"NEGATIVE_count\"] = [x.count(\"NEGATIVE\") for x in gr_df[\"STUDSENT_label_rComments_tags\"]]\n",
    "\n",
    "gr_df.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_df.to_csv(\"agg_group_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = gr_df.all_rComments_tags.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import os, spacy\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from transformers.pipelines import pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap, hdbscan\n",
    "import gc\n",
    "\n",
    "verbose = True\n",
    "rand_state = 59910214\n",
    "\n",
    "nn_list = [20]\n",
    "nc_list = [2]\n",
    "lr_list = [0.05]\n",
    "md_list = [0.01]\n",
    "m_list = [\"cosine\"]\n",
    "\n",
    "min_cluster_size_list = [10]\n",
    "\n",
    "ng_list = [(1, 3)]\n",
    "\n",
    "tnw_list = [10]\n",
    "mts_list = [10]\n",
    "nrt_list = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TOPIC MODELS:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1238/1238 [12:53<00:00,  1.60it/s]\n",
      "2022-11-02 13:47:18,046 - BERTopic - Transformed documents to Embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(angular_rp_forest=True, learning_rate=0.05, metric='cosine', min_dist=0.01, n_epochs=500, n_neighbors=20, random_state=59910214, verbose=True)\n",
      "Wed Nov  2 13:47:18 2022 Construct fuzzy simplicial set\n",
      "Wed Nov  2 13:47:19 2022 Finding Nearest Neighbors\n",
      "Wed Nov  2 13:47:20 2022 Finished Nearest Neighbor Search\n",
      "Wed Nov  2 13:47:21 2022 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56879c44f4f649e693f3bd3e196abfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/500 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 13:47:23,806 - BERTopic - Reduced dimensionality\n",
      "2022-11-02 13:47:23,854 - BERTopic - Clustered reduced embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  2 13:47:23 2022 Finished embedding\n",
      "NUMBER OF TOPICS INN:/Classes/2022_2FALL/Analytics Day/topic_model/topic_model_0 = 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_model_bert = pipeline(\n",
    "                                \"feature-extraction\", \n",
    "                                model = \"sentence-transformers/all-mpnet-base-v2\" #\"distilbert-base-cased\"\n",
    "                               )\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "umap_model_list = []\n",
    "for nn in nn_list:\n",
    "    for nc in nc_list:\n",
    "        for lr in lr_list:\n",
    "            for md in md_list:\n",
    "                for m in m_list:\n",
    "                    umap_model = UMAP(\n",
    "                                      n_neighbors = nn,             # int 2-100, doc neighborhood\n",
    "                                      n_components = nc,            # int 2-100, doc dimensionality\n",
    "                                      n_epochs = 500,              # None 'or' 200 (large dataframes) 'or' 500 (small dataframes)\n",
    "                                      learning_rate = lr,          # float\n",
    "                                    #   init = \"spectral\",            # string spectral, random, pca 'or' np.array \n",
    "                                      min_dist = md,               # float 0.1 (default)\n",
    "                                      metric = m,             # string euclidean, manhattan, chebyshev, minkowski, canberra, braycurtis, mahalanobis, wminkowski, seuclidean, cosine, correlation, haversine, hamming, jaccard, dice, russelrao, kulsinski, ll_dirichlet, hellinger, rogerstanimoto, sokalmichener, sokalsneath, yule\n",
    "                                      verbose = verbose,\n",
    "                                      random_state = rand_state\n",
    "                                     )\n",
    "                    umap_model_list.append([umap_model, nn, nc, lr, md, m])\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "\n",
    "hdbscan_model_list = []\n",
    "for mcsl in min_cluster_size_list:\n",
    "    hdbscan_model = HDBSCAN(\n",
    "                            min_cluster_size = mcsl,                  # The minimum size of clusters; single linkage splits that contain fewer points than this will be considered points \"falling out\" of a cluster rather than a cluster splitting into two new clusters.\n",
    "                            metric = \"euclidean\",\n",
    "                            prediction_data = True,\n",
    "                            gen_min_span_tree = True,               # Whether to generate the minimum spanning tree with regard to mutual reachability distance for later analysis.\n",
    "                            # cluster_selection_method = \"eom\",\n",
    "                            # approx_min_span_tree = True,          # Default = False\n",
    "                            # allow_single_cluster = False,\n",
    "                            # min_samples = None,                     # The number of samples in a neighbourhood for a point to be considered a core point.\n",
    "                            # cluster_selection_epsilon = 0,\n",
    "                            # max_cluster_size = 0,\n",
    "                            # alpha = 1,\n",
    "                            # p = None,\n",
    "                            # algorithm = \"best\",\n",
    "                            # leaf_size = 40,\n",
    "                            # match_reference_implementation = False  # There exist some interpretational differences between this HDBSCAN* implementation and the original authors reference implementation in Java. \n",
    "                            )\n",
    "    hdbscan_model_list.append([hdbscan_model, mcsl])\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "\n",
    "vectorizer_model_list = [[CountVectorizer(ngram_range = ng, stop_words = \"english\"), ng] for ng in ng_list]\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words = True)\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "import time \n",
    "\n",
    "print(\"NUMBER OF TOPIC MODELS: \", len(hdbscan_model_list)*len(umap_model_list)*len(vectorizer_model_list)*len(tnw_list)*len(mts_list)*len(nrt_list))\n",
    "\n",
    "i = 0\n",
    "bertopic_list = []\n",
    "for hdbscan_model in hdbscan_model_list:\n",
    "    for umap_model in umap_model_list: \n",
    "        for vectorizer_model in vectorizer_model_list:\n",
    "            for tnw in tnw_list:\n",
    "                for mts in mts_list:\n",
    "                    for nrt in nrt_list:\n",
    "                        model_nm = \"N:/Classes/2022_2FALL/Analytics Day/topic_model/topic_model_\" + str(i)\n",
    "                        start_time = time.time()\n",
    "                        topic_model = BERTopic(\n",
    "                                            verbose = verbose,\n",
    "                                            language = \"english\",\n",
    "                                            top_n_words = tnw,\n",
    "                                            min_topic_size = mts,\n",
    "                                            nr_topics = nrt,\n",
    "                                            low_memory = False,\n",
    "                                            calculate_probabilities = True,\n",
    "                                            embedding_model = embedding_model_bert,\n",
    "                                            umap_model = umap_model[0],\n",
    "                                            hdbscan_model = hdbscan_model[0],\n",
    "                                            vectorizer_model = vectorizer_model[0],\n",
    "                                            ctfidf_model = ctfidf_model,\n",
    "                                            )\n",
    "\n",
    "                        # Fit the model and predict documents\n",
    "                        topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "                        end_time = time.time()\n",
    "                        time_diff = end_time - start_time\n",
    "\n",
    "                        num_topics = len(topic_model.get_topic_info().Topic.tolist())\n",
    "\n",
    "                        print(\"NUMBER OF TOPICS IN\" + model_nm.split(\"/\")[-1] + \" =\", num_topics)\n",
    "                        topic_model.save(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1_knowing blind makes_person advisor_sense do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1182</td>\n",
       "      <td>0_class_professor_good_teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1_history_mr_mr swann_swann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2_comments comments comments_comments comments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3_class_gives_lectures_homework</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                               Name\n",
       "0     -1      6  -1_knowing blind makes_person advisor_sense do...\n",
       "1      0   1182                     0_class_professor_good_teacher\n",
       "2      1     18                        1_history_mr_mr swann_swann\n",
       "3      2     16  2_comments comments comments_comments comments...\n",
       "4      3     16                    3_class_gives_lectures_homework"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEID</th>\n",
       "      <th>school_sid</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>school_year</th>\n",
       "      <th>WDRAW_ORIG_YR2_RT</th>\n",
       "      <th>STUDSENT_label_rComments_tags</th>\n",
       "      <th>STUDSENT_score_rComments_tags</th>\n",
       "      <th>AVGSTUDSENT</th>\n",
       "      <th>all_rComments_tags</th>\n",
       "      <th>POSITIVE_count</th>\n",
       "      <th>NEGATIVE_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154100</td>\n",
       "      <td>2</td>\n",
       "      <td>Abraham Baldwin Agricultural College</td>\n",
       "      <td>2002_03</td>\n",
       "      <td>0.244068</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[0.0007101297378540039]</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>It was an awful experience in her class. I had...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154100</td>\n",
       "      <td>2</td>\n",
       "      <td>Abraham Baldwin Agricultural College</td>\n",
       "      <td>2002_03</td>\n",
       "      <td>0.244068</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[0.6046267151832581, 0.9998801946640016, 0.999...</td>\n",
       "      <td>0.933969</td>\n",
       "      <td>She has a great personality very real person. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154100</td>\n",
       "      <td>2</td>\n",
       "      <td>Abraham Baldwin Agricultural College</td>\n",
       "      <td>2003_04</td>\n",
       "      <td>0.202791</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[0.025868237018585205, 0.025868237018585205, 0...</td>\n",
       "      <td>0.019522</td>\n",
       "      <td>No Comments No Comments real rude teacher No C...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154100</td>\n",
       "      <td>2</td>\n",
       "      <td>Abraham Baldwin Agricultural College</td>\n",
       "      <td>2003_04</td>\n",
       "      <td>0.202791</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[0.9989988207817078, 0.999451220035553, 0.9998...</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>good teacher explains concepts well easy to gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154100</td>\n",
       "      <td>2</td>\n",
       "      <td>Abraham Baldwin Agricultural College</td>\n",
       "      <td>2004_05</td>\n",
       "      <td>0.255489</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[0.03511732816696156, 0.00030398368835438117, ...</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>she is a great teacher if you come to school t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>4142900</td>\n",
       "      <td>12000</td>\n",
       "      <td>Georgia Gwinnett College</td>\n",
       "      <td>2017_18</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[0.0033588409423828125, 0.3874475359916687, 0....</td>\n",
       "      <td>0.037531</td>\n",
       "      <td>Way too much work for a easy class. More work ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>4142900</td>\n",
       "      <td>12000</td>\n",
       "      <td>Georgia Gwinnett College</td>\n",
       "      <td>2017_18</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[0.9998517036437988, 0.8986119627952576, 0.999...</td>\n",
       "      <td>0.981319</td>\n",
       "      <td>I loved Dr. Abraham she was so positive and he...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>4142900</td>\n",
       "      <td>12000</td>\n",
       "      <td>Georgia Gwinnett College</td>\n",
       "      <td>2018_19</td>\n",
       "      <td>0.375807</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>[0.00023621320724476202, 0.000922083854675182,...</td>\n",
       "      <td>0.033858</td>\n",
       "      <td>Worst Most boring professor in the history of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>4142900</td>\n",
       "      <td>12000</td>\n",
       "      <td>Georgia Gwinnett College</td>\n",
       "      <td>2018_19</td>\n",
       "      <td>0.375807</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[0.9983384609222412, 0.9997201561927797, 0.999...</td>\n",
       "      <td>0.985685</td>\n",
       "      <td>She was an awesome professor. We did a project...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>10145912</td>\n",
       "      <td>4683</td>\n",
       "      <td>Strayer University - Macon Campus</td>\n",
       "      <td>2018_19</td>\n",
       "      <td>0.436345</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>[0.9996258020401]</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>Professor Samia gives good lectures with actua...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2356 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         OPEID  school_sid                                INSTNM school_year  \\\n",
       "0       154100           2  Abraham Baldwin Agricultural College     2002_03   \n",
       "1       154100           2  Abraham Baldwin Agricultural College     2002_03   \n",
       "2       154100           2  Abraham Baldwin Agricultural College     2003_04   \n",
       "3       154100           2  Abraham Baldwin Agricultural College     2003_04   \n",
       "4       154100           2  Abraham Baldwin Agricultural College     2004_05   \n",
       "...        ...         ...                                   ...         ...   \n",
       "2351   4142900       12000              Georgia Gwinnett College     2017_18   \n",
       "2352   4142900       12000              Georgia Gwinnett College     2017_18   \n",
       "2353   4142900       12000              Georgia Gwinnett College     2018_19   \n",
       "2354   4142900       12000              Georgia Gwinnett College     2018_19   \n",
       "2355  10145912        4683     Strayer University - Macon Campus     2018_19   \n",
       "\n",
       "      WDRAW_ORIG_YR2_RT STUDSENT_label_rComments_tags  \\\n",
       "0              0.244068                      NEGATIVE   \n",
       "1              0.244068                      POSITIVE   \n",
       "2              0.202791                      NEGATIVE   \n",
       "3              0.202791                      POSITIVE   \n",
       "4              0.255489                      NEGATIVE   \n",
       "...                 ...                           ...   \n",
       "2351           0.344749                      NEGATIVE   \n",
       "2352           0.344749                      POSITIVE   \n",
       "2353           0.375807                      NEGATIVE   \n",
       "2354           0.375807                      POSITIVE   \n",
       "2355           0.436345                      POSITIVE   \n",
       "\n",
       "                          STUDSENT_score_rComments_tags  AVGSTUDSENT  \\\n",
       "0                               [0.0007101297378540039]     0.000710   \n",
       "1     [0.6046267151832581, 0.9998801946640016, 0.999...     0.933969   \n",
       "2     [0.025868237018585205, 0.025868237018585205, 0...     0.019522   \n",
       "3     [0.9989988207817078, 0.999451220035553, 0.9998...     0.999478   \n",
       "4     [0.03511732816696156, 0.00030398368835438117, ...     0.021032   \n",
       "...                                                 ...          ...   \n",
       "2351  [0.0033588409423828125, 0.3874475359916687, 0....     0.037531   \n",
       "2352  [0.9998517036437988, 0.8986119627952576, 0.999...     0.981319   \n",
       "2353  [0.00023621320724476202, 0.000922083854675182,...     0.033858   \n",
       "2354  [0.9983384609222412, 0.9997201561927797, 0.999...     0.985685   \n",
       "2355                                  [0.9996258020401]     0.999626   \n",
       "\n",
       "                                     all_rComments_tags  POSITIVE_count  \\\n",
       "0     It was an awful experience in her class. I had...               0   \n",
       "1     She has a great personality very real person. ...               1   \n",
       "2     No Comments No Comments real rude teacher No C...               0   \n",
       "3     good teacher explains concepts well easy to gr...               1   \n",
       "4     she is a great teacher if you come to school t...               0   \n",
       "...                                                 ...             ...   \n",
       "2351  Way too much work for a easy class. More work ...               0   \n",
       "2352  I loved Dr. Abraham she was so positive and he...               1   \n",
       "2353  Worst Most boring professor in the history of ...               0   \n",
       "2354  She was an awesome professor. We did a project...               1   \n",
       "2355  Professor Samia gives good lectures with actua...               1   \n",
       "\n",
       "      NEGATIVE_count  \n",
       "0                  1  \n",
       "1                  0  \n",
       "2                  1  \n",
       "3                  0  \n",
       "4                  1  \n",
       "...              ...  \n",
       "2351               1  \n",
       "2352               0  \n",
       "2353               1  \n",
       "2354               0  \n",
       "2355               0  \n",
       "\n",
       "[2356 rows x 11 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5210f08b43caa98193ac4cc30e63606a904c7d72d37a54875ef48f7a7b311874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
