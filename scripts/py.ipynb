{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"N:/Classes/2022_2FALL/Analytics Day/Data/RollerCoasterDataRATINGS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coaster                                              Superman The Escape\n",
       "Park                                            Six Flags Magic Mountain\n",
       "Rating                                                               4.0\n",
       "Top_10_Wooden                                                          0\n",
       "Top_10_Steel                                                           0\n",
       "Top_10_Biggest_Drop                                                    0\n",
       "Top_10_Longest_Length                                                  0\n",
       "Top_10_Fastest                                                         1\n",
       "Top_10_Inversions                                                    0.0\n",
       "Top_10_Duration                                                        0\n",
       "Total_Num_Top_10                                                       1\n",
       "Any_Top_10                                                             1\n",
       "City                                                            Valencia\n",
       "State                                                         California\n",
       "Type                                                               Steel\n",
       "Design                                                          Sit Down\n",
       "Year_Opened                                                         1997\n",
       "Top_Speed                                                          100.0\n",
       "Max_Height                                                           415\n",
       "Drop                                                               328.0\n",
       "Length                                                              1235\n",
       "Duration                                                            28.0\n",
       "Inversions                                                             N\n",
       "Num_of_Inversions                                                    0.0\n",
       "coaster_park             Superman The Escape at Six Flags Magic Mountain\n",
       "city_state                                          Valencia, California\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"coaster_park\"] = df[\"Coaster\"] + \" at \" + df[\"Park\"]\n",
    "\n",
    "df[\"city_state\"] = df[\"City\"] + \", \" + df[\"State\"]\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\ProgramFiles\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "temp = []\n",
    "for keyword in df[\"city_state\"].drop_duplicates().tolist():\n",
    "    try:\n",
    "        keyword = keyword.replace(\";\", \":\")\n",
    "        wiki_suggestion = \"\"\n",
    "        search_results = wikipedia.search(keyword, results = 1)\n",
    "\n",
    "        if search_results == []:\n",
    "            wiki_suggestion = wikipedia.suggest(keyword)\n",
    "            search_results = wikipedia.search(wiki_suggestion, results = 1)\n",
    "\n",
    "        wiki_page = wikipedia.page(search_results)\n",
    "\n",
    "        try:\n",
    "            lat = float(wiki_page.coordinates[0])\n",
    "            lon = float(wiki_page.coordinates[1])\n",
    "        except:\n",
    "            lat = None\n",
    "            lon = None\n",
    "\n",
    "        temp.append([keyword, wiki_page.title, wiki_page.url, lat, lon])\n",
    "    except:\n",
    "        temp.append([keyword, None, None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF CITIES LAT/LONG PULLED: 62\n",
      "NUMBER OF CITIES THAT PULL FAILED: 8\n"
     ]
    }
   ],
   "source": [
    "temp_df = pd.DataFrame(temp, columns = [\"city_state\", \"title\", \"url\", \"latitude\", \"longitude\"])\n",
    "\n",
    "print(\"NUMBER OF CITIES LAT/LONG PULLED:\", temp_df[temp_df[\"latitude\"].isna() == False].drop_duplicates().shape[0])\n",
    "print(\"NUMBER OF CITIES THAT PULL FAILED:\", temp_df[temp_df[\"latitude\"].isna() == True].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_state</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Diego, California</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wisconsin Dells, Wisconsin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Louisville,_Kent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Branson, Missouri</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Santa Claus, Indiana</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>https://en.wikipedia.org/wiki/San_Antonio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Branson , Missouri</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Lake George, New York</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city_state                 title  \\\n",
       "4        San Diego, California                  None   \n",
       "7   Wisconsin Dells, Wisconsin                  None   \n",
       "8         Louisville, Kentucky  Louisville, Kentucky   \n",
       "20           Branson, Missouri                  None   \n",
       "26        Santa Claus, Indiana                  None   \n",
       "29          San Antonio, Texas           San Antonio   \n",
       "40          Branson , Missouri                  None   \n",
       "46       Lake George, New York                  None   \n",
       "\n",
       "                                                  url  latitude  longitude  \n",
       "4                                                None       NaN        NaN  \n",
       "7                                                None       NaN        NaN  \n",
       "8   https://en.wikipedia.org/wiki/Louisville,_Kent...       NaN        NaN  \n",
       "20                                               None       NaN        NaN  \n",
       "26                                               None       NaN        NaN  \n",
       "29          https://en.wikipedia.org/wiki/San_Antonio       NaN        NaN  \n",
       "40                                               None       NaN        NaN  \n",
       "46                                               None       NaN        NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df[\"latitude\"].isna() == True].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_latlon = pd.merge(left = df.reset_index().drop(\"index\", axis = 1),\n",
    "                       right = temp_df[[\"city_state\", \"latitude\", \"longitude\"]].reset_index().drop(\"index\", axis = 1),\n",
    "                       how = \"left\",\n",
    "                       left_on = \"city_state\",\n",
    "                       right_on = \"city_state\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_latlon.drop([\"coaster_park\", \"city_state\"], axis = 1).to_csv(\"city_state_latlon.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5210f08b43caa98193ac4cc30e63606a904c7d72d37a54875ef48f7a7b311874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
